{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MidTerm Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of Words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "# CountVectorizer(lowercase=False)\n",
    "# CountVectorizer()\n",
    "# print(vectorizer.get_stop_words())\n",
    "sentences = \"\"\"\n",
    "Regularly and thoroughly clean your hands with an alcohol-based hand rub or wash them with soap and water.\n",
    "This eliminates germs including viruses that may be on your hands.\n",
    "Avoid touching your eyes, nose and mouth.\n",
    "Hands touch many surfaces and can pick up viruses.\n",
    "Once contaminated, hands can transfer the virus to your eyes, nose or mouth.\n",
    "From there, the virus can enter your body and infect you.\n",
    "Cover your mouth and nose with your bent elbow or tissue when you cough or sneeze.\n",
    "Then dispose of the used tissue immediately into a closed bin and wash your hands.\n",
    "By following good ‘respiratory hygiene’, you protect the people around you from viruses, which cause colds, flu and COVID-19.\n",
    "Clean and disinfect surfaces frequently especially those which are regularly touched,\n",
    "such as door handles, faucets and phone screens or mouth.\n",
    "From there, the virus can enter your body and infect you.\n",
    "\"\"\"\n",
    "tokenized_sentences = nltk.sent_tokenize(sentences)\n",
    "vectorized_counter = vectorizer.fit(tokenized_sentences)\n",
    "print(vectorized_counter.vocabulary_)  # the numbers are the place in the array for which the number stands"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorized_counter.vocabulary_.get('wash')  # just to get the number for wash"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ft = vectorizer.fit_transform(tokenized_sentences)\n",
    "count_array = ft.toarray()\n",
    "print(count_array)\n",
    "# print(count_array.shape)  # 11 sentences, and 60 unique words in these sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count_token = vectorizer.get_feature_names_out()\n",
    "count_token"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_countvect = pd.DataFrame(data=count_array, columns=count_token)\n",
    "df_countvect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF_IDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(tokenized_sentences)\n",
    "df_tfidfvect = pd.DataFrame(\n",
    "    data=tfidf_matrix.toarray(),\n",
    "    columns=tfidf.get_feature_names_out()\n",
    ")\n",
    "print(df_tfidfvect)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_count = pd.DataFrame({\n",
    "    'words': tfidf.get_feature_names_out(),\n",
    "    'tf-idf score': tfidf_matrix.sum(axis=0).flat\n",
    "})\n",
    "word_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_count.sort_values(by=['tf-idf score'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('week7/imdb_dataset.csv', nrows=10000, encoding='cp949')\n",
    "# encoding: just test which one works: utf-8, utf-16, euc-kr, cp949, latin_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PREPROCESSING\n",
    "import pandas as pd\n",
    "\n",
    "reviews = pd.DataFrame(imdb)\n",
    "#print(reviews)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "import re\n",
    "\n",
    "\n",
    "def filter(review):\n",
    "    review_regexed = re.sub(r'<.*?>', '', review)\n",
    "    review_filtered = (word for word in review_regexed.split() if word not in stop_words)\n",
    "    return \" \".join(review_filtered)\n",
    "\n",
    "\n",
    "# reviews['review processed'] = (filter(review) for review in reviews['review']) this is wrong for some reason\n",
    "reviews['review processed'] = reviews['review'].apply(lambda rev: filter(rev))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "reviews['polarity'] = reviews['review processed'].apply(lambda rev: TextBlob(rev).polarity)\n",
    "reviews['subjectivity'] = reviews['review processed'].apply(lambda rev: TextBlob(rev).subjectivity)\n",
    "print(reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "% matplotlib inline\n",
    "sns.displot(reviews['polarity'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  Nice to Know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(print(x) for x in range(1, 11))  # from 1 to 10 ToDo warum geht das nicht??????"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}