{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentences = \"\"\"\n",
    "Regularly and thoroughly clean your hands with an alcohol-based hand rub or wash them with soap and water. \n",
    "This eliminates germs including viruses that may be on your hands.\n",
    "Avoid touching your eyes, nose and mouth. \n",
    "Hands touch many surfaces and can pick up viruses. \n",
    "Once contaminated, hands can transfer the virus to your eyes, nose or mouth. \n",
    "From there, the virus can enter your body and infect you.\n",
    "Cover your mouth and nose with your bent elbow or tissue when you cough or sneeze. \n",
    "Then dispose of the used tissue immediately into a closed bin and wash your hands.\n",
    "By following good ‘respiratory hygiene’, you protect the people around you from viruses, which cause colds, flu and COVID-19.\n",
    "Clean and disinfect surfaces frequently especially those which are regularly touched, \n",
    "such as door handles, faucets and phone screens or mouth. \n",
    "From there, the virus can enter your body and infect you.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_sent = nltk.sent_tokenize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Let's try vectorizer.fit first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularly': 58, 'and': 3, 'thoroughly': 72, 'clean': 16, 'your': 90, 'hands': 40, 'with': 88, 'an': 2, 'alcohol': 1, 'based': 8, 'hand': 38, 'rub': 60, 'or': 53, 'wash': 84, 'them': 68, 'soap': 63, 'water': 85, 'this': 71, 'eliminates': 27, 'germs': 36, 'including': 43, 'viruses': 83, 'that': 66, 'may': 47, 'be': 9, 'on': 51, 'avoid': 7, 'touching': 78, 'eyes': 30, 'nose': 49, 'mouth': 48, 'touch': 76, 'many': 46, 'surfaces': 65, 'can': 14, 'pick': 56, 'up': 80, 'once': 52, 'contaminated': 19, 'transfer': 79, 'the': 67, 'virus': 82, 'to': 75, 'from': 35, 'there': 70, 'enter': 28, 'body': 12, 'infect': 44, 'you': 89, 'cover': 21, 'bent': 10, 'elbow': 26, 'tissue': 74, 'when': 86, 'cough': 20, 'sneeze': 62, 'then': 69, 'dispose': 24, 'of': 50, 'used': 81, 'immediately': 42, 'into': 45, 'closed': 17, 'bin': 11, 'by': 13, 'following': 33, 'good': 37, 'respiratory': 59, 'hygiene': 41, 'protect': 57, 'people': 54, 'around': 5, 'which': 87, 'cause': 15, 'colds': 18, 'flu': 32, 'covid': 22, '19': 0, 'disinfect': 23, 'frequently': 34, 'especially': 29, 'those': 73, 'are': 4, 'touched': 77, 'such': 64, 'as': 6, 'door': 25, 'handles': 39, 'faucets': 31, 'phone': 55, 'screens': 61}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit(tokenized_sent)\n",
    "print(X.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Regularly': 9, 'and': 14, 'thoroughly': 76, 'clean': 25, 'your': 94, 'hands': 47, 'with': 92, 'an': 13, 'alcohol': 12, 'based': 18, 'hand': 45, 'rub': 66, 'or': 59, 'wash': 88, 'them': 74, 'soap': 69, 'water': 89, 'This': 11, 'eliminates': 34, 'germs': 43, 'including': 50, 'viruses': 87, 'that': 72, 'may': 54, 'be': 19, 'on': 58, 'Avoid': 1, 'touching': 82, 'eyes': 37, 'nose': 56, 'mouth': 55, 'Hands': 7, 'touch': 80, 'many': 53, 'surfaces': 71, 'can': 23, 'pick': 62, 'up': 84, 'Once': 8, 'contaminated': 28, 'transfer': 83, 'the': 73, 'virus': 86, 'to': 79, 'From': 6, 'there': 75, 'enter': 35, 'body': 22, 'infect': 51, 'you': 93, 'Cover': 5, 'bent': 20, 'elbow': 33, 'tissue': 78, 'when': 90, 'cough': 29, 'sneeze': 68, 'Then': 10, 'dispose': 31, 'of': 57, 'used': 85, 'immediately': 49, 'into': 52, 'closed': 26, 'bin': 21, 'By': 2, 'following': 40, 'good': 44, 'respiratory': 65, 'hygiene': 48, 'protect': 63, 'people': 60, 'around': 16, 'from': 42, 'which': 91, 'cause': 24, 'colds': 27, 'flu': 39, 'COVID': 3, '19': 0, 'Clean': 4, 'disinfect': 30, 'frequently': 41, 'especially': 36, 'those': 77, 'are': 15, 'regularly': 64, 'touched': 81, 'such': 70, 'as': 17, 'door': 32, 'handles': 46, 'faucets': 38, 'phone': 61, 'screens': 67}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "X = vectorizer.fit(tokenized_sent)\n",
    "print(X.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularly': 42, 'thoroughly': 49, 'clean': 8, 'hands': 31, 'alcohol': 1, 'based': 3, 'hand': 29, 'rub': 44, 'wash': 58, 'soap': 47, 'water': 59, 'eliminates': 19, 'germs': 27, 'including': 34, 'viruses': 57, 'avoid': 2, 'touching': 53, 'eyes': 22, 'nose': 37, 'mouth': 36, 'touch': 51, 'surfaces': 48, 'pick': 40, 'contaminated': 11, 'transfer': 54, 'virus': 56, 'enter': 20, 'body': 6, 'infect': 35, 'cover': 13, 'bent': 4, 'elbow': 18, 'tissue': 50, 'cough': 12, 'sneeze': 46, 'dispose': 16, 'used': 55, 'immediately': 33, 'closed': 9, 'bin': 5, 'following': 25, 'good': 28, 'respiratory': 43, 'hygiene': 32, 'protect': 41, 'people': 38, 'cause': 7, 'colds': 10, 'flu': 24, 'covid': 14, '19': 0, 'disinfect': 15, 'frequently': 26, 'especially': 21, 'touched': 52, 'door': 17, 'handles': 30, 'faucets': 23, 'phone': 39, 'screens': 45}\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "x = vectorizer.fit(tokenized_sent)\n",
    "print(x.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'few', 'amoungst', 'because', 'either', 'whereby', 'yours', 'upon', 'system', 'be', 'will', 'mill', 'most', 'yourselves', 'two', 'though', 'up', 'rather', 'bill', 'everything', 'why', 'would', 'of', 'how', 'towards', 'ten', 'sincere', 'hereby', 'already', 'so', 'anyhow', 'nine', 'hereafter', 'mostly', 'herself', 'hasnt', 'see', 'any', 'every', 'next', 'moreover', 're', 'which', 'after', 'eleven', 'twenty', 'around', 'each', 'however', 'per', 'might', 'yet', 'latterly', 'when', 'your', 'even', 'yourself', 'full', 'beyond', 'formerly', 'both', 'some', 'almost', 'had', 'off', 'hereupon', 'thereupon', 'front', 'or', 'fifty', 'never', 'out', 'part', 'besides', 'ever', 'now', 'eg', 'thereafter', 'anything', 'back', 'below', 'put', 'between', 'whereafter', 'behind', 'to', 'whenever', 'they', 'alone', 'made', 'once', 'often', 'hers', 'his', 'cannot', 'latter', 'still', 'fire', 'for', 'was', 'ie', 'along', 'meanwhile', 'at', 'via', 'its', 'itself', 'more', 'many', 'give', 'not', 'wherever', 'about', 'throughout', 'neither', 'been', 'together', 'those', 'them', 'there', 'are', 'anywhere', 'the', 'themselves', 'always', 'except', 'someone', 'serious', 'get', 'must', 'whatever', 'seemed', 'detail', 'above', 'last', 'elsewhere', 'no', 'somewhere', 'first', 'move', 'me', 'in', 'you', 'done', 'nor', 'anyway', 'becoming', 'can', 'as', 'several', 'un', 'cant', 'show', 'less', 'twelve', 'keep', 'this', 'her', 'fifteen', 'others', 'but', 'only', 'nobody', 'other', 'further', 'my', 'whole', 'on', 'an', 'he', 'we', 'seem', 'myself', 'across', 'it', 'may', 'by', 'and', 'con', 'has', 'hundred', 'am', 'everywhere', 'although', 'again', 'hence', 'is', 'none', 'i', 'where', 'what', 'couldnt', 'beforehand', 'de', 'please', 'whom', 'name', 'noone', 'thence', 'something', 'us', 'seems', 'than', 'toward', 'amount', 'bottom', 'our', 'ours', 'interest', 'take', 'eight', 'five', 'become', 'co', 'side', 'thru', 'empty', 'herein', 'third', 'then', 'should', 'have', 'etc', 'four', 'much', 'also', 'a', 'she', 'who', 'these', 'one', 'whither', 'could', 'inc', 'whoever', 'within', 'through', 'into', 'somehow', 'three', 'six', 'wherein', 'found', 'otherwise', 'that', 'since', 'own', 'ltd', 'forty', 'until', 'mine', 'enough', 'whereas', 'call', 'thus', 'such', 'do', 'same', 'against', 'therein', 'least', 'very', 'from', 'himself', 'became', 'nowhere', 'whether', 'due', 'without', 'find', 'nothing', 'all', 'indeed', 'too', 'here', 'whereupon', 'thereby', 'sometime', 'beside', 'describe', 'becomes', 'well', 'him', 'were', 'if', 'among', 'afterwards', 'go', 'another', 'namely', 'under', 'therefore', 'onto', 'anyone', 'ourselves', 'whose', 'sixty', 'former', 'seeming', 'top', 'being', 'before', 'sometimes', 'thin', 'thick', 'during', 'perhaps', 'while', 'their', 'whence', 'with', 'fill', 'amongst', 'nevertheless', 'cry', 'down', 'everyone', 'else', 'over'})\n"
     ]
    },
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vectorizer.get_stop_words())  # to see the stopwords of the library\n",
    "x.vocabulary_.get('clean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Now let's try using fit_transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0\n",
      "  0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0\n",
      "  1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "ft = vectorizer.fit_transform(tokenized_sent)\n",
    "count_array = ft.toarray()\n",
    "print(count_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 60)\n"
     ]
    }
   ],
   "source": [
    "print(count_array.shape)  #There are 11 sentences, and there are 60 unique words in these sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['19', 'alcohol', 'avoid', 'based', 'bent', 'bin', 'body', 'cause',\n       'clean', 'closed', 'colds', 'contaminated', 'cough', 'cover',\n       'covid', 'disinfect', 'dispose', 'door', 'elbow', 'eliminates',\n       'enter', 'especially', 'eyes', 'faucets', 'flu', 'following',\n       'frequently', 'germs', 'good', 'hand', 'handles', 'hands',\n       'hygiene', 'immediately', 'including', 'infect', 'mouth', 'nose',\n       'people', 'phone', 'pick', 'protect', 'regularly', 'respiratory',\n       'rub', 'screens', 'sneeze', 'soap', 'surfaces', 'thoroughly',\n       'tissue', 'touch', 'touched', 'touching', 'transfer', 'used',\n       'virus', 'viruses', 'wash', 'water'], dtype=object)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_token = vectorizer.get_feature_names_out()\n",
    "count_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    19  alcohol  avoid  based  bent  bin  body  cause  clean  closed  ...  \\\n0    0        1      0      1     0    0     0      0      1       0  ...   \n1    0        0      0      0     0    0     0      0      0       0  ...   \n2    0        0      1      0     0    0     0      0      0       0  ...   \n3    0        0      0      0     0    0     0      0      0       0  ...   \n4    0        0      0      0     0    0     0      0      0       0  ...   \n5    0        0      0      0     0    0     1      0      0       0  ...   \n6    0        0      0      0     1    0     0      0      0       0  ...   \n7    0        0      0      0     0    1     0      0      0       1  ...   \n8    1        0      0      0     0    0     0      1      0       0  ...   \n9    0        0      0      0     0    0     0      0      1       0  ...   \n10   0        0      0      0     0    0     1      0      0       0  ...   \n\n    tissue  touch  touched  touching  transfer  used  virus  viruses  wash  \\\n0        0      0        0         0         0     0      0        0     1   \n1        0      0        0         0         0     0      0        1     0   \n2        0      0        0         1         0     0      0        0     0   \n3        0      1        0         0         0     0      0        1     0   \n4        0      0        0         0         1     0      1        0     0   \n5        0      0        0         0         0     0      1        0     0   \n6        1      0        0         0         0     0      0        0     0   \n7        1      0        0         0         0     1      0        0     1   \n8        0      0        0         0         0     0      0        1     0   \n9        0      0        1         0         0     0      0        0     0   \n10       0      0        0         0         0     0      1        0     0   \n\n    water  \n0       1  \n1       0  \n2       0  \n3       0  \n4       0  \n5       0  \n6       0  \n7       0  \n8       0  \n9       0  \n10      0  \n\n[11 rows x 60 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>19</th>\n      <th>alcohol</th>\n      <th>avoid</th>\n      <th>based</th>\n      <th>bent</th>\n      <th>bin</th>\n      <th>body</th>\n      <th>cause</th>\n      <th>clean</th>\n      <th>closed</th>\n      <th>...</th>\n      <th>tissue</th>\n      <th>touch</th>\n      <th>touched</th>\n      <th>touching</th>\n      <th>transfer</th>\n      <th>used</th>\n      <th>virus</th>\n      <th>viruses</th>\n      <th>wash</th>\n      <th>water</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 60 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countvect = pd.DataFrame(data=count_array, columns=count_token)\n",
    "df_countvect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf_results = tfidf.fit_transform(tokenized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_token = tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          19   alcohol     avoid     based      bent       bin      body  \\\n",
      "0   0.000000  0.323429  0.000000  0.323429  0.000000  0.000000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.516605  0.000000  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.514793   \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.384986  0.000000  0.000000   \n",
      "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.382666  0.000000   \n",
      "8   0.294053  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.514793   \n",
      "\n",
      "       cause     clean    closed  ...    tissue     touch   touched  touching  \\\n",
      "0   0.000000  0.276455  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.516605   \n",
      "3   0.000000  0.000000  0.000000  ...  0.000000  0.522457  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.000000  0.000000  ...  0.329072  0.000000  0.000000  0.000000   \n",
      "7   0.000000  0.000000  0.382666  ...  0.327089  0.000000  0.000000  0.000000   \n",
      "8   0.294053  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "9   0.000000  0.250502  0.000000  ...  0.000000  0.000000  0.293065  0.000000   \n",
      "10  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "    transfer      used     virus   viruses      wash     water  \n",
      "0   0.000000  0.000000  0.000000  0.000000  0.276455  0.323429  \n",
      "1   0.000000  0.000000  0.000000  0.379051  0.000000  0.000000  \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3   0.000000  0.000000  0.000000  0.392740  0.000000  0.000000  \n",
      "4   0.462255  0.000000  0.347485  0.000000  0.000000  0.000000  \n",
      "5   0.000000  0.000000  0.452731  0.000000  0.000000  0.000000  \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "7   0.000000  0.382666  0.000000  0.000000  0.327089  0.000000  \n",
      "8   0.000000  0.000000  0.000000  0.221045  0.000000  0.000000  \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "10  0.000000  0.000000  0.452731  0.000000  0.000000  0.000000  \n",
      "\n",
      "[11 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "df_tfidfvect = pd.DataFrame(data=tf_results.toarray(), columns=tfidf_token)\n",
    "print(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           words  tf-idf score\n0             19      0.294053\n1        alcohol      0.323429\n2          avoid      0.516605\n3          based      0.323429\n4           bent      0.384986\n5            bin      0.382666\n6           body      1.029585\n7          cause      0.294053\n8          clean      0.526957\n9         closed      0.382666\n10         colds      0.294053\n11  contaminated      0.462255\n12         cough      0.384986\n13         cover      0.384986\n14         covid      0.294053\n15     disinfect      0.293065\n16       dispose      0.382666\n17          door      0.293065\n18         elbow      0.384986\n19    eliminates      0.504247\n20         enter      1.029585\n21    especially      0.293065\n22          eyes      0.836694\n23       faucets      0.293065\n24           flu      0.294053\n25     following      0.294053\n26    frequently      0.293065\n27         germs      0.504247\n28          good      0.294053\n29          hand      0.323429\n30       handles      0.293065\n31         hands      1.331257\n32       hygiene      0.294053\n33   immediately      0.382666\n34     including      0.504247\n35        infect      1.029585\n36         mouth      1.113092\n37          nose      1.025226\n38        people      0.294053\n39         phone      0.293065\n40          pick      0.522457\n41       protect      0.294053\n42     regularly      0.526957\n43   respiratory      0.294053\n44           rub      0.323429\n45       screens      0.293065\n46        sneeze      0.384986\n47          soap      0.323429\n48      surfaces      0.697079\n49    thoroughly      0.323429\n50        tissue      0.656161\n51         touch      0.522457\n52       touched      0.293065\n53      touching      0.516605\n54      transfer      0.462255\n55          used      0.382666\n56         virus      1.252948\n57       viruses      0.992836\n58          wash      0.603544\n59         water      0.323429",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>tf-idf score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>alcohol</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>avoid</td>\n      <td>0.516605</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>based</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bent</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bin</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>body</td>\n      <td>1.029585</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>cause</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>clean</td>\n      <td>0.526957</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>closed</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>colds</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>contaminated</td>\n      <td>0.462255</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>cough</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>cover</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>covid</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>disinfect</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>dispose</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>door</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>elbow</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>eliminates</td>\n      <td>0.504247</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>enter</td>\n      <td>1.029585</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>especially</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>eyes</td>\n      <td>0.836694</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>faucets</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>flu</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>following</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>frequently</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>germs</td>\n      <td>0.504247</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>good</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>hand</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>handles</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>hands</td>\n      <td>1.331257</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>hygiene</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>immediately</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>including</td>\n      <td>0.504247</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>infect</td>\n      <td>1.029585</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>mouth</td>\n      <td>1.113092</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>nose</td>\n      <td>1.025226</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>people</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>phone</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>pick</td>\n      <td>0.522457</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>protect</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>regularly</td>\n      <td>0.526957</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>respiratory</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>rub</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>screens</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>sneeze</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>soap</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>surfaces</td>\n      <td>0.697079</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>thoroughly</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>tissue</td>\n      <td>0.656161</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>touch</td>\n      <td>0.522457</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>touched</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>touching</td>\n      <td>0.516605</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>transfer</td>\n      <td>0.462255</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>used</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>virus</td>\n      <td>1.252948</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>viruses</td>\n      <td>0.992836</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>wash</td>\n      <td>0.603544</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>water</td>\n      <td>0.323429</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = pd.DataFrame({\n",
    "    'words': tfidf_token,\n",
    "    'tf-idf score': tf_results.sum(axis=0).flat\n",
    "})\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           words  tf-idf score\n31         hands      1.331257\n56         virus      1.252948\n36         mouth      1.113092\n20         enter      1.029585\n35        infect      1.029585\n6           body      1.029585\n37          nose      1.025226\n57       viruses      0.992836\n22          eyes      0.836694\n48      surfaces      0.697079\n50        tissue      0.656161\n58          wash      0.603544\n42     regularly      0.526957\n8          clean      0.526957\n51         touch      0.522457\n40          pick      0.522457\n53      touching      0.516605\n2          avoid      0.516605\n34     including      0.504247\n19    eliminates      0.504247\n27         germs      0.504247\n11  contaminated      0.462255\n54      transfer      0.462255\n18         elbow      0.384986\n13         cover      0.384986\n12         cough      0.384986\n4           bent      0.384986\n46        sneeze      0.384986\n5            bin      0.382666\n33   immediately      0.382666\n16       dispose      0.382666\n9         closed      0.382666\n55          used      0.382666\n3          based      0.323429\n44           rub      0.323429\n47          soap      0.323429\n1        alcohol      0.323429\n29          hand      0.323429\n49    thoroughly      0.323429\n59         water      0.323429\n43   respiratory      0.294053\n0             19      0.294053\n41       protect      0.294053\n38        people      0.294053\n7          cause      0.294053\n32       hygiene      0.294053\n28          good      0.294053\n10         colds      0.294053\n25     following      0.294053\n24           flu      0.294053\n14         covid      0.294053\n17          door      0.293065\n15     disinfect      0.293065\n23       faucets      0.293065\n21    especially      0.293065\n52       touched      0.293065\n39         phone      0.293065\n26    frequently      0.293065\n45       screens      0.293065\n30       handles      0.293065",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>tf-idf score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31</th>\n      <td>hands</td>\n      <td>1.331257</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>virus</td>\n      <td>1.252948</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>mouth</td>\n      <td>1.113092</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>enter</td>\n      <td>1.029585</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>infect</td>\n      <td>1.029585</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>body</td>\n      <td>1.029585</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>nose</td>\n      <td>1.025226</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>viruses</td>\n      <td>0.992836</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>eyes</td>\n      <td>0.836694</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>surfaces</td>\n      <td>0.697079</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>tissue</td>\n      <td>0.656161</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>wash</td>\n      <td>0.603544</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>regularly</td>\n      <td>0.526957</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>clean</td>\n      <td>0.526957</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>touch</td>\n      <td>0.522457</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>pick</td>\n      <td>0.522457</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>touching</td>\n      <td>0.516605</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>avoid</td>\n      <td>0.516605</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>including</td>\n      <td>0.504247</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>eliminates</td>\n      <td>0.504247</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>germs</td>\n      <td>0.504247</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>contaminated</td>\n      <td>0.462255</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>transfer</td>\n      <td>0.462255</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>elbow</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>cover</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>cough</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bent</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>sneeze</td>\n      <td>0.384986</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bin</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>immediately</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>dispose</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>closed</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>used</td>\n      <td>0.382666</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>based</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>rub</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>soap</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>alcohol</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>hand</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>thoroughly</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>water</td>\n      <td>0.323429</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>respiratory</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>protect</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>people</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>cause</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>hygiene</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>good</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>colds</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>following</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>flu</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>covid</td>\n      <td>0.294053</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>door</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>disinfect</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>faucets</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>especially</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>touched</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>phone</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>frequently</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>screens</td>\n      <td>0.293065</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>handles</td>\n      <td>0.293065</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.sort_values(by=['tf-idf score'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}